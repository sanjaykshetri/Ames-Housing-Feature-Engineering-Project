{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbcdca53",
   "metadata": {},
   "source": [
    "### Dataset source\n",
    "\n",
    "**Ames Housing Dataset** (via Kaggle â€“ \"House Prices: Advanced Regression Techniques\")\n",
    "\n",
    "Files you'll use:\n",
    "\n",
    "* `train.csv` â†’ for model development\n",
    "* (`test.csv` exists, but you won't touch it yet for this capstone step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82624d28",
   "metadata": {},
   "source": [
    "### Project structure (recommended)\n",
    "\n",
    "```text\n",
    "capstone_two/\n",
    "â”‚\n",
    "â”œâ”€â”€ data/\n",
    "â”‚   â”œâ”€â”€ raw/\n",
    "â”‚   â”‚   â””â”€â”€ train.csv\n",
    "â”‚\n",
    "â”œâ”€â”€ notebooks/\n",
    "â”‚   â””â”€â”€ 01_preprocessing.ipynb\n",
    "â”‚\n",
    "â””â”€â”€ README.md\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61494d16",
   "metadata": {},
   "source": [
    "### Load the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba2cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load raw dataset\n",
    "df = pd.read_csv(\"../data/raw/train.csv\")\n",
    "\n",
    "# Basic sanity check\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9217d141",
   "metadata": {},
   "source": [
    "### Initial shape and structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf618fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992a45cd",
   "metadata": {},
   "source": [
    "> Expect ~1,460 rows and ~81 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c781fe4c",
   "metadata": {},
   "source": [
    "### Column data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a10310",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af19f06",
   "metadata": {},
   "source": [
    "**What you're looking for (and should mention in markdown):**\n",
    "\n",
    "* Mix of numeric and categorical features\n",
    "* Some integer-like columns actually represent *categories* (e.g., `OverallQual`)\n",
    "* Missing values present in multiple columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87bb8f2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Initial Data Inspection & Cleaning\n",
    "\n",
    "> âš ï¸ This step is **not** full preprocessing yet.\n",
    "> No scaling. No dummies.\n",
    "> Just understanding and light cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4add62d",
   "metadata": {},
   "source": [
    "### Target variable inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682fad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SalePrice\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec60dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(df[\"SalePrice\"], bins=30)\n",
    "plt.title(\"Distribution of Sale Prices\")\n",
    "plt.xlabel(\"SalePrice\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d283f885",
   "metadata": {},
   "source": [
    "ðŸ“Œ **Note:**\n",
    "\n",
    "* SalePrice is right-skewed\n",
    "* Possible log-transform later (but **don't do it yet**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb710e6",
   "metadata": {},
   "source": [
    "### Missing value overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5af92d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df.isnull().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "\n",
    "missing.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a68a7b8",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "* Missingness is **systematic**, not random\n",
    "* Some missing values mean *\"feature not applicable\"* (e.g., no alley, no pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9c338a",
   "metadata": {},
   "source": [
    "### Separate feature types (important later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33140401",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "numeric_cols = df.select_dtypes(include=[\"number\"]).columns\n",
    "\n",
    "len(categorical_cols), len(numeric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e17e88",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "* Categorical features will require **dummy/indicator encoding**\n",
    "* Numeric features span **very different scales** â†’ scaling required later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aab75a",
   "metadata": {},
   "source": [
    "### Minimal cleaning (Step-2 appropriate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71043f76",
   "metadata": {},
   "source": [
    "We **do NOT** fully impute yet.\n",
    "We only fix things that would break basic inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c67025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize column names (optional but clean)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Remove duplicate rows if any\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee6c03a",
   "metadata": {},
   "source": [
    "### Explicitly document what you are *not* doing yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6c90f5",
   "metadata": {},
   "source": [
    "> At this stage, no feature engineering, encoding, or scaling has been performed.\n",
    "> These steps will be completed in the preprocessing phase after the trainâ€“test split to prevent data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb3017f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Checkpoint: What you've accomplished so far\n",
    "\n",
    "By the end of Steps 1 & 2, your notebook clearly shows:\n",
    "\n",
    "âœ… Raw dataset obtained and loaded  \n",
    "âœ… Structure, shape, and feature types understood  \n",
    "âœ… Target variable inspected  \n",
    "âœ… Missing data patterns identified  \n",
    "âœ… Light, justified cleaning only\n",
    "\n",
    "You are **exactly where the rubric expects you to be**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b150ca",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next up (Step 3 preview â€” don't do yet)\n",
    "\n",
    "* Train/test split\n",
    "* Imputation\n",
    "* One-hot encoding\n",
    "* Scaling via `StandardScaler`\n",
    "* `ColumnTransformer` pipeline\n",
    "\n",
    "When you're ready, say:\n",
    "**\"Proceed to Step 3 (trainâ€“test split + preprocessing pipeline)\"**\n",
    "and we'll finish this capstone like professionals."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
